model3.1 <- lmer(promotion ~ gender + (1|employee_id), data = promotion)
model3.1 <- lm(promotion ~ gender, data = promotion)
summary(model3.1)
confint(model3.1)
model3.1 <- glm(promotion ~ gender, data = promotion)
kable(tidy(model3.1))
summary(model3.1)
# The reduced model from the main model
# Tried team for level from the predictors and the reduced model has a worse performance comparing to the full model
#
model1.6 <- lmer(salary ~ gender + seniority + quarter + (1|team)  + (1|employee_id)  + (1|leadership_for_level), data = current)
summary(model1.6)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.1, model1.6)
# The reduced model from the main model
# Tried team for level from the predictors and the reduced model has a worse performance comparing to the full model
#
model1.6 <- lmer(salary ~ gender + seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
summary(model1.6)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.1, model1.6)
# The reduced model from the main model
# Tried team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original
model1.6 <- lmer(salary ~ gender + seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
summary(model1.6)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.1, model1.6)
# The reduced model from the main model
# Tried team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model1.6 <- lmer(salary ~ gender +  quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
summary(model1.5)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.5, model1.6)
# The reduced model from the main model
# Tried seniority, team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model1.6 <- lmer(salary ~ seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
summary(model1.5)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.5, model1.6)
# The reduced model from the main model
# Tried seniority, team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model1.6 <- lmer(salary ~ gender + seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
summary(model1.5)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.5, model1.6)
# pass_phase1 ~ gender* cv gpa cover_letter (phase1)
model2.1 <- glm(pass_phase1 ~ gender + gpa + extracurriculars + cv + work_experience, family = binomial(link = "logit"), data = phase1_new_applicants)
library(lmtest)
library(tidyverse)
library(cowplot)
library(lme4)
library(ggpubr)
library(knitr)
library(tableone)
library(broom)
#install.packages("tableone")
# this should supress all code and messages
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
# Import cleaned data
current <- read_csv("clean/current.csv")
promotion <- read_csv("clean/promotion.csv")
final_hires <- read_csv("clean/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("clean/phase1_new.csv")
phase2_new_applicants <- read_csv("clean/phase2_new.csv")
phase3_new_applicants <- read_csv("clean/phase3_new.csv")
# The main model examine the gender bias, along with other potential biases in current employee remuneration
# Removed "Prefer not to say" from gender since it doesn't provide additional information
# With productivity the model doesn't converge, so I removed productivity for this model
# fixed effect: gender, seniority, quarter
# random effect: team, leadership, productivity
current <- current %>% filter(gender != "Prefer not to say")
model1.1 <- lmer(salary ~ gender + seniority + quarter + (1|productivity) + (1|employee_id) + (1|team) + (1|leadership_for_level), data = current)
summary(model1.1)
confint(model1.1)
# there exists correlation between gender and productivity according to the data given
model1.2 <- glm(productivity ~ gender, data = current)
kable(tidy(model1.2))
summary(model1.2)
#This model shows that there is a difference in salary between male and female, but there might be other reasons why the gap exists
model1.3 <- glm(salary ~ gender, data = current)
kable(tidy(model1.3))
summary(model1.3)
confint(model1.3)
# there exists negative correlation between salary and productivity according to the data given
# worth to mention in the report: higher productivity leads to lower salary
model1.4 <- glm(salary ~ productivity, data = current)
kable(tidy(model1.4))
summary(model1.4)
# The reduced model from the main model - this can be the final model I think
# Tried seniority, gender, quarter, employeeid, team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model1.5 <- lmer(salary ~ gender + seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
summary(model1.5)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.1, model1.5)
# pass_phase1 ~ gender* cv gpa cover_letter (phase1)
model2.1 <- glm(pass_phase1 ~ gender + gpa + extracurriculars + cv + work_experience, family = binomial(link = "logit"), data = phase1_new_applicants)
View(promotion)
promotion %>% ggplot(aes(x = gender, y = promotion)) + geom_boxplot()
# there exists correlation between gender and productivity according to the data given
model1.2 <- glm(productivity ~ gender, data = current)
kable(tidy(model1.2))
summary(model1.2)
# pass_phase1 ~ gender* cv gpa cover_letter (phase1)
model2.1 <- glm(pass_phase1 ~ gender + gpa + extracurriculars + cv + work_experience, family = binomial(link = "logit"), data = phase1_new_applicants)
# Import cleaned data
current <- read_csv("clean/current.csv")
promotion <- read_csv("clean/promotion.csv")
final_hires <- read_csv("clean/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("clean/phase1_new.csv")
phase2_new_applicants <- read_csv("clean/phase2_new.csv")
phase3_new_applicants <- read_csv("clean/phase3_new.csv")
# pass_phase1 ~ gender* cv gpa cover_letter (phase1)
model2.1 <- glm(pass_phase1 ~ gender + gpa + extracurriculars + cv + work_experience, family = binomial(link = "logit"), data = phase1_new_applicants)
write.csv(phase3_new_applicants, "../output/clean/phase3_new.csv")
phase1_new_applicants
library(lmtest)
library(tidyverse)
library(cowplot)
library(lme4)
library(ggpubr)
library(knitr)
library(tableone)
library(broom)
#install.packages("tableone")
# this should supress all code and messages
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
# Import cleaned data
current <- read_csv("clean/current.csv")
promotion <- read_csv("clean/promotion.csv")
final_hires <- read_csv("clean/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("clean/phase1_new.csv")
phase2_new_applicants <- read_csv("clean/phase2_new.csv")
phase3_new_applicants <- read_csv("clean/phase3_new.csv")
# The main model examine the gender bias, along with other potential biases in current employee remuneration
# Removed "Prefer not to say" from gender since it doesn't provide additional information
# fixed effect: gender, seniority, quarter
# random effect: team, leadership, productivity
current <- current %>% filter(gender != "Prefer not to say")
model1.1 <- lmer(salary ~ gender + seniority + quarter + (1|productivity) + (1|employee_id) + (1|team) + (1|leadership_for_level), data = current)
summary(model1.1)
confint(model1.1)
# there exists correlation between gender and productivity according to the data given
model1.2 <- glm(productivity ~ gender, data = current)
kable(tidy(model1.2))
summary(model1.2)
#This model shows that there is a difference in salary between male and female, but there might be other reasons why the gap exists
model1.3 <- glm(salary ~ gender, data = current)
kable(tidy(model1.3))
summary(model1.3)
confint(model1.3)
# there exists negative correlation between salary and productivity according to the data given
# worth to mention in the report: higher productivity leads to lower salary
model1.4 <- glm(salary ~ productivity, data = current)
kable(tidy(model1.4))
summary(model1.4)
# The reduced model from the main model - this can be the final model I think
# Tried seniority, gender, quarter, employeeid, team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model1.5 <- lmer(salary ~ gender + seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
summary(model1.5)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.1, model1.5)
phase1_new_applicants
# pass_phase1 ~ gender* cv gpa cover_letter (phase1)
model2.1 <- glm(pass_phase1 ~ gender + gpa + extracurriculars + cv + work_experience, family = binomial(link = "logit"), data = phase1_new_applicants)
model2.4 <- glm(final_hired ~ gpa, family = binomial(link = "logit"), data = phase1_new_applicants)
model2.4 <- glm(final_hired.x ~ gpa, family = binomial(link = "logit"), data = phase1_new_applicants)
summary(model2.4)
View(final_hires)
View(phase1_new_applicants)
View(phase2_temp)
final_hires <- read_csv("../input/data/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("../input/data/phase1-new-grad-applicants-2020.csv")
phase2_new_applicants <- read_csv("../input/data/phase2-new-grad-applicants-2020.csv")
phase3_new_applicants <- read_csv("../input/data/phase3-new-grad-applicants-2020.csv")
phase1_new_applicants <- phase1_new_applicants %>%
merge(final_hires, by = "applicant_id", all = TRUE) %>% merge(phase2_temp, by = "applicant_id" & "pass_phase1", all = TRUE)
phase1_new_applicants
# pass_phase1 ~ gender* cv gpa cover_letter (phase1)
model2.1 <- glm(pass_phase1.x ~ gender + gpa + extracurriculars + cv + work_experience, family = binomial(link = "logit"), data = phase1_new_applicants)
View(phase1_new_applicants)
phase1_new_applicants
# pass_phase1 ~ gender* cv gpa cover_letter (phase1)
model2.1 <- glm(pass_phase1.x ~ gender + gpa + extracurriculars + cv + work_experience, family = binomial(link = "logit"), data = phase1_new_applicants)
#### Workspace setup ####
if (!require("remotes")) install.packages("remotes")
remotes::install_github("AndriSignorell/DescTools")
# Import cleaned data
current <- read_csv("clean/current.csv")
promotion <- read_csv("clean/promotion.csv")
final_hires <- read_csv("clean/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("clean/phase1_new.csv")
phase2_new_applicants <- read_csv("clean/phase2_new.csv")
phase3_new_applicants <- read_csv("clean/phase3_new.csv")
# Import cleaned data
current <- read_csv("clean/current.csv")
promotion <- read_csv("clean/promotion.csv")
final_hires <- read_csv("clean/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("clean/phase1_new.csv")
phase2_new_applicants <- read_csv("clean/phase2_new.csv")
phase3_new_applicants <- read_csv("clean/phase3_new.csv")
phase1_new_applicants
# pass_phase1 ~ gender* cv gpa cover_letter (phase1)
model2.1 <- glm(pass_phase1.x ~ gender + gpa + extracurriculars + cv + work_experience, family = binomial(link = "logit"), data = phase1_new_applicants)
summary(model2.1)
# pass_phase2 ~ gender* cv gpa cover_letter tech writing speaking (phase2)
# everyone passed phase 1 has cv
model2.2 <- glm(pass_phase2 ~ gender + team_applied_for + extracurriculars + work_experience + technical_skills + writing_skills + leadership_presence + speaking_skills, family = binomial(link = "logit"), data = phase2_new_applicants)
# pass_phase2 ~ gender* cv gpa cover_letter tech writing speaking (phase2)
# everyone passed phase 1 has cv
model2.2 <- glm(pass_phase2.x ~ gender + team_applied_for + extracurriculars + work_experience + technical_skills + writing_skills + leadership_presence + speaking_skills, family = binomial(link = "logit"), data = phase2_new_applicants)
summary(model2.2)
# final_hired ~ gender* cv gpa cover_letter tech writing speaking rating1 rating2 (phase3)
# everyone passed phase 1 has cv
# too few datapoints model can't converge... the only model that can converge is to use gender
phase3_new_applicants <- phase3_new_applicants %>% mutate(avg = (interviewer_rating_1+interviewer_rating_2)/2)
model2.3 <- glm(final_hired ~ gender, family = binomial(link = "logit"), data = phase3_new_applicants)
# final_hired ~ gender* cv gpa cover_letter tech writing speaking rating1 rating2 (phase3)
# everyone passed phase 1 has cv
# too few datapoints model can't converge... the only model that can converge is to use gender
phase3_new_applicants <- phase3_new_applicants %>% mutate(avg = (interviewer_rating_1+interviewer_rating_2)/2)
model2.3 <- glm(final_hired.x ~ gender, family = binomial(link = "logit"), data = phase3_new_applicants)
View(phase3_new_applicants)
# final_hired ~ gender* cv gpa cover_letter tech writing speaking rating1 rating2 (phase3)
# everyone passed phase 1 has cv
# too few datapoints model can't converge... the only model that can converge is to use gender
phase3_new_applicants <- phase3_new_applicants %>% mutate(avg = (interviewer_rating_1+interviewer_rating_2)/2)
model2.3 <- glm(final_hired.x.x ~ gender, family = binomial(link = "logit"), data = phase3_new_applicants)
# final_hired ~ gender* cv gpa cover_letter tech writing speaking rating1 rating2 (phase3)
# everyone passed phase 1 has cv
# too few datapoints model can't converge... the only model that can converge is to use gender
phase3_new_applicants <- phase3_new_applicants %>% mutate(avg = (interviewer_rating_1+interviewer_rating_2)/2)
model2.3 <- glm(final_hired.x.x ~ gender.x, family = binomial(link = "logit"), data = phase3_new_applicants)
summary(model2.3)
#table(phase3_new_applicants$gender, phase3_new_applicants$final_hired)
table(phase3_new_applicants$avg)
library(lmtest)
library(tidyverse)
library(cowplot)
library(lme4)
library(ggpubr)
install.packages("ggpubr")
install.packages("ggpubr")
install.packages("ggpubr")
library(lmtest)
library(tidyverse)
library(cowplot)
library(lme4)
library(ggpubr)
library(knitr)
library(tableone)
install.pacakges("tableone")
install.packages("tableone")
library(lmtest)
library(tidyverse)
library(cowplot)
library(lme4)
library(ggpubr)
library(knitr)
library(tableone)
library(broom)
library(psycho)
install.packages("psycho")
library(lmtest)
library(tidyverse)
library(cowplot)
library(lme4)
library(ggpubr)
library(knitr)
library(tableone)
library(broom)
library(psycho)
#install.packages("tableone")
# this should supress all code and messages
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
library(lmtest)
library(tidyverse)
library(cowplot)
library(lme4)
library(ggpubr)
library(knitr)
library(tableone)
library(broom)
library(psycho)
#install.packages("tableone")
# this should supress all code and messages
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
# Import cleaned data
current <- read_csv("clean/current.csv")
promotion <- read_csv("clean/promotion.csv")
final_hires <- read_csv("clean/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("clean/phase1_new.csv")
phase2_new_applicants <- read_csv("clean/phase2_new.csv")
phase3_new_applicants <- read_csv("clean/phase3_new.csv")
# The main model examine the gender bias, along with other potential biases in current employee remuneration
# Removed "Prefer not to say" from gender since it doesn't provide additional information
# fixed effect: gender, seniority, quarter
# random effect: team, leadership, productivity
current <- current %>% filter(gender != "Prefer not to say")
model1.1 <- lmer(salary ~ gender + seniority + quarter + (1|productivity) + (1|employee_id) + (1|team) + (1|leadership_for_level), data = current)
summary(model1.1)
# confint(model1.1)
# there exists correlation between gender and productivity according to the data given
model1.2 <- glm(productivity ~ gender, data = current)
kable(tidy(model1.2))
summary(model1.2)
#This model shows that there is a difference in salary between male and female, but there might be other reasons why the gap exists
model1.3 <- glm(salary ~ gender, data = current)
kable(tidy(model1.3))
summary(model1.3)
confint(model1.3)
# there exists negative correlation between salary and productivity according to the data given
# worth to mention in the report: higher productivity leads to lower salary
model1.4 <- glm(salary ~ productivity, data = current)
kable(tidy(model1.4))
summary(model1.4)
# The reduced model from the main model - this can be the final model I think
# Tried seniority, gender, quarter, employeeid, team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model1.5 <- lmer(salary ~ gender + seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
summary(model1.5)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.1, model1.5)
phase1_new_applicants
# pass_phase1 ~ gender* cv gpa cover_letter (phase1)
model2.1 <- glm(pass_phase1.x ~ gender + gpa + extracurriculars + cv + work_experience, family = binomial(link = "logit"), data = phase1_new_applicants)
summary(model2.1)
# pass_phase2 ~ gender* cv gpa cover_letter tech writing speaking (phase2)
# everyone passed phase 1 has cv
model2.2 <- glm(pass_phase2.x ~ gender + team_applied_for + extracurriculars + work_experience + technical_skills + writing_skills + leadership_presence + speaking_skills, family = binomial(link = "logit"), data = phase2_new_applicants)
summary(model2.2)
# final_hired ~ gender* cv gpa cover_letter tech writing speaking rating1 rating2 (phase3)
# everyone passed phase 1 has cv
# too few datapoints model can't converge... the only model that can converge is to use gender
phase3_new_applicants <- phase3_new_applicants %>% mutate(avg = (interviewer_rating_1+interviewer_rating_2)/2)
model2.3 <- glm(final_hired.x.x ~ gender.x, family = binomial(link = "logit"), data = phase3_new_applicants)
summary(model2.3)
#table(phase3_new_applicants$gender, phase3_new_applicants$final_hired)
table(phase3_new_applicants$avg)
model2.4 <- glm(final_hired.x ~ gpa, family = binomial(link = "logit"), data = phase1_new_applicants)
summary(model2.4)
promotion %>% ggplot(aes(x = gender, y = promotion)) + geom_boxplot()
model3.1 <- glm(promotion ~ gender, data = promotion)
kable(tidy(model3.1))
summary(model3.1)
#edit axis label (name)
salary_by_gender_q1 <- current %>% filter(substring(financial_q, nchar(financial_q)) == '1') %>% ggplot(aes(x = gender, y = salary)) + geom_boxplot(aes(colour = gender)) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
salary_by_gender_q2 <- current %>% filter(substring(financial_q, nchar(financial_q)) == '1') %>% ggplot(aes(x = gender, y = salary)) + geom_boxplot(aes(colour = gender)) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
salary_by_gender_q3 <- current %>% filter(substring(financial_q, nchar(financial_q)) == '1') %>% ggplot(aes(x = gender, y = salary)) + geom_boxplot(aes(colour = gender))+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
salary_by_gender_q4 <- current %>% filter(substring(financial_q, nchar(financial_q)) == '1') %>% ggplot(aes(x = gender, y = salary)) + geom_boxplot(aes(colour = gender))+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
gender_salary <- plot_grid(salary_by_gender_q1, salary_by_gender_q2, salary_by_gender_q3, salary_by_gender_q4, labels = c("Q1","Q2","Q3","Q4"), ncol = 2, nrow = 2)
gender_salary
ldr_slry <- current %>%
filter(financial_q == '2020 Q1') %>%
group_by(employee_id) %>%
ggplot(aes(x = productivity, y = salary, color = as.factor(leadership_for_level)))+
geom_point()+
labs(color = "Leadership for Level")
ldr_slry
lvl_slry <- current %>%
filter(financial_q == '2020 Q1') %>%
group_by(employee_id) %>%
ggplot(aes(x = productivity, y = salary, color = as.factor(role_seniority)))+
geom_point()+
labs(color = "Seniority")
lvl_slry
pro_slry <- current %>%
filter(financial_q == '2020 Q1') %>%
group_by(employee_id) %>%
ggplot(aes(x = productivity, y = salary, color = as.factor(gender)))+
geom_point()+
labs(color = "gender")
pro_slry
current %>%
filter(financial_q == '2020 Q4') %>%
filter(role_seniority == 'Entry-level') %>%
group_by(employee_id) %>%
ggplot(aes(x = team, y = salary, color = as.factor(gender)))+
geom_point()+ theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))+
labs(color = "gender")
#ggsave("images/leadership_salary_Q1.png", width = 7, height = 4)
current %>%
filter(financial_q == '2020 Q4') %>%
filter(role_seniority == 'Junior I') %>%
group_by(employee_id) %>%
ggplot(aes(x = team, y = salary, color = as.factor(gender)))+
geom_point()+ theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))+
labs(color = "gender")
current %>%
filter(financial_q == '2020 Q4') %>%
filter(role_seniority == 'Senior I') %>%
group_by(employee_id) %>%
ggplot(aes(x = team, y = salary, color = as.factor(gender)))+
geom_point()+ theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))+
labs(color = "gender")
current %>%
filter(financial_q == '2020 Q4') %>%
filter(role_seniority == 'Manager') %>%
group_by(employee_id) %>%
ggplot(aes(x = team, y = salary, color = as.factor(gender)))+
geom_point()+ theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))+
labs(color = "gender")
current %>%
group_by(employee_id) %>%
ggplot(aes(x = leadership_for_level, y = salary, color = as.factor(gender)))+
geom_point()+
labs(color = "gender")+
xlab("leadership for level")+ theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))+
labs(color = "gender")
current %>%
group_by(employee_id) %>%
ggplot(aes(x = role_seniority, y = salary, color = as.factor(gender)))+
geom_point()+ theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))+
labs(color = "gender")+
xlab("seniority")
current %>%
group_by(employee_id) %>%
ggplot(aes(x = team, y = salary, color = as.factor(gender)))+
geom_point()+ theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))+
labs(color = "gender")
phase1_new_applicants %>% ggplot(aes(x = as.character(gender), y = gpa)) + geom_boxplot()+
xlab("gender")
#ggsave("images/gpa_hiring.png", gpa_if_hired)
# gpa_if_hired <- phase1_new_applicants %>% ggplot(aes(x = as.character(final_hired), y = gpa)) + geom_boxplot()+
xlab("hiring results")
# gpa_if_hired
# gpa_if_pass_phase1 <- phase1_new_applicants %>% ggplot(aes(x = as.character(pass_phase1), y = gpa)) + geom_boxplot()+
#   xlab("phase1 results")
# gpa_if_pass_phase1
#same scale
# phase2_new_applicants %>% ggplot(aes(x = as.character(final_hired), y = speaking_skills)) + geom_boxplot()+
#   xlab("hiring results")+ylab("speaking skills score")
#same scale
# phase2_new_applicants %>% ggplot(aes(x = as.character(pass_phase2), y = speaking_skills)) + geom_boxplot()+
# xlab("phase2 results")+ylab("speaking skills score")
# phase2_new_applicants %>% ggplot(aes(x = as.character(final_hired), y = writing_skills)) + geom_boxplot()+
# xlab("hiring results")+ylab("writing skills score")
# phase2_new_applicants %>% ggplot(aes(x = as.character(pass_phase2), y = writing_skills)) + geom_boxplot()+
# xlab("phase2 results")+ylab("writing skills score")
# phase2_new_applicants %>% ggplot(aes(x = as.character(final_hired), y = technical_skills)) + geom_boxplot()+
# xlab("hiring results")+ylab("technical skills score")
# phase1_new_applicants %>%
# filter(final_hired == '1') %>%
# group_by(applicant_id) %>%
# ggplot(aes(x = gender, y = gpa))+
# geom_point()
# phase2_new_applicants %>%
# filter(final_hired == '1') %>%
# group_by(applicant_id) %>%
# ggplot(aes(x = gender, y = technical_skills))+
# geom_point()
# phase2_new_applicants %>%
# filter(final_hired == '1') %>%
# group_by(applicant_id) %>%
# ggplot(aes(x = gender, y = writing_skills))+
# geom_point()
# phase2_new_applicants %>%
# filter(final_hired == '1') %>%
# group_by(applicant_id) %>%
# ggplot(aes(x = gender, y = speaking_skills))+
# geom_point()
# The main model examine the gender bias, along with other potential biases in current employee remuneration
# Removed "Prefer not to say" from gender since it doesn't provide additional information
# fixed effect: gender, seniority, quarter
# random effect: team, leadership, productivity
current <- current %>% filter(gender != "Prefer not to say")
model1.1 <- lmer(salary ~ gender + seniority + quarter + (1|productivity) + (1|employee_id) + (1|team) + (1|leadership_for_level), data = current)
summary(model1.1)
confint(model1.1)
View(current)
unique(current$role_seniority)
# there exists correlation between gender and productivity according to the data given
model1.2 <- glm(productivity ~ gender, data = current)
kable(tidy(model1.2))
summary(model1.2)
#This model shows that there is a difference in salary between male and female, but there might be other reasons why the gap exists
model1.3 <- glm(salary ~ gender, data = current)
kable(tidy(model1.3))
summary(model1.3)
confint(model1.3)
# there exists correlation between gender and productivity according to the data given
model1.2 <- glm(productivity ~ gender, data = current)
kable(tidy(model1.2))
summary(model1.2)
#This model shows that there is a difference in salary between male and female, but there might be other reasons why the gap exists
model1.3 <- glm(salary ~ gender, data = current)
kable(tidy(model1.3))
summary(model1.3)
confint(model1.3)
# there exists negative correlation between salary and productivity according to the data given
# worth to mention in the report: higher productivity leads to lower salary
model1.4 <- glm(salary ~ productivity, data = current)
kable(tidy(model1.4))
summary(model1.4)
# there exists correlation between gender and productivity according to the data given
model1.2 <- glm(productivity ~ gender, data = current)
kable(tidy(model1.2))
summary(model1.2)
