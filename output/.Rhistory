# Import cleaned data
current <- read_csv("clean/current.csv")
promotion <- read_csv("clean/promotion.csv")
final_hires <- read_csv("clean/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("clean/phase1_new.csv")
phase2_new_applicants <- read_csv("clean/phase2_new.csv")
phase3_new_applicants <- read_csv("clean/phase3_new.csv")
# The main model examine the gender bias, along with other potential biases in current employee remuneration
# Removed "Prefer not to say" from gender since it doesn't provide additional information
# With productivity the model doesn't converge, so I removed productivity for this model
# fixed effect: gender, seniority, quarter
# random effect: team, leadership, productivity
current <- current %>% filter(gender != "Prefer not to say")
model1.1 <- lmer(salary ~ gender + seniority + quarter + (1|productivity) + (1|employee_id) + (1|team) + (1|leadership_for_level), data = current)
summary(model1.1)
confint(model1.1)
# there exists correlation between gender and productivity according to the data given
model1.2 <- glm(productivity ~ gender, data = current)
kable(tidy(model1.2))
summary(model1.2)
#This model shows that there is a difference in salary between male and female, but there might be other reasons why the gap exists
model1.3 <- glm(salary ~ gender, data = current)
kable(tidy(model1.3))
summary(model1.3)
confint(model1.3)
# there exists negative correlation between salary and productivity according to the data given
# worth to mention in the report: higher productivity leads to lower salary
model1.4 <- glm(salary ~ productivity, data = current)
kable(tidy(model1.4))
summary(model1.4)
# The reduced model from the main model
# Removed financial quarter from the predictors and the reduced model has a worse performance comparing to the original model
model1.5 <- lmer(salary ~ gender + seniority + (1|employee_id) + (1|team) + (1|leadership_for_level), data = current)
summary(model1.5)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
#lmtest::lrtest(model1.1, model1.5)
# The reduced model from the main model
# Removed team for level from the predictors and the reduced model has a better performance comparing to
model1.6 <- lmer(salary ~ gender + seniority + quarter + (1|productivity) + (1|employee_id)  + (1|leadership_for_level), data = current)
summary(model1.6)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.1, model1.6)
promotion
model3.1 <- lmer(promotion ~ gender, data = promotion)
model3.1 <- lmer(promotion ~ gender + (1|employee_id), data = promotion)
model3.1 <- lm(promotion ~ gender, data = promotion)
summary(model3.1)
confint(model3.1)
model3.1 <- glm(promotion ~ gender, data = promotion)
kable(tidy(model3.1))
summary(model3.1)
# The reduced model from the main model
# Tried team for level from the predictors and the reduced model has a worse performance comparing to the full model
#
model1.6 <- lmer(salary ~ gender + seniority + quarter + (1|team)  + (1|employee_id)  + (1|leadership_for_level), data = current)
summary(model1.6)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.1, model1.6)
# The reduced model from the main model
# Tried team for level from the predictors and the reduced model has a worse performance comparing to the full model
#
model1.6 <- lmer(salary ~ gender + seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
summary(model1.6)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.1, model1.6)
# The reduced model from the main model
# Tried team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original
model1.6 <- lmer(salary ~ gender + seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
summary(model1.6)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.1, model1.6)
# The reduced model from the main model
# Tried team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model1.6 <- lmer(salary ~ gender +  quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
summary(model1.5)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.5, model1.6)
# The reduced model from the main model
# Tried seniority, team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model1.6 <- lmer(salary ~ seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
summary(model1.5)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.5, model1.6)
# The reduced model from the main model
# Tried seniority, team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model1.6 <- lmer(salary ~ gender + seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
summary(model1.5)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.5, model1.6)
# pass_phase1 ~ gender* cv gpa cover_letter (phase1)
model2.1 <- glm(pass_phase1 ~ gender + gpa + extracurriculars + cv + work_experience, family = binomial(link = "logit"), data = phase1_new_applicants)
library(lmtest)
library(tidyverse)
library(cowplot)
library(lme4)
library(ggpubr)
library(knitr)
library(tableone)
library(broom)
#install.packages("tableone")
# this should supress all code and messages
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
# Import cleaned data
current <- read_csv("clean/current.csv")
promotion <- read_csv("clean/promotion.csv")
final_hires <- read_csv("clean/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("clean/phase1_new.csv")
phase2_new_applicants <- read_csv("clean/phase2_new.csv")
phase3_new_applicants <- read_csv("clean/phase3_new.csv")
# The main model examine the gender bias, along with other potential biases in current employee remuneration
# Removed "Prefer not to say" from gender since it doesn't provide additional information
# With productivity the model doesn't converge, so I removed productivity for this model
# fixed effect: gender, seniority, quarter
# random effect: team, leadership, productivity
current <- current %>% filter(gender != "Prefer not to say")
model1.1 <- lmer(salary ~ gender + seniority + quarter + (1|productivity) + (1|employee_id) + (1|team) + (1|leadership_for_level), data = current)
summary(model1.1)
confint(model1.1)
# there exists correlation between gender and productivity according to the data given
model1.2 <- glm(productivity ~ gender, data = current)
kable(tidy(model1.2))
summary(model1.2)
#This model shows that there is a difference in salary between male and female, but there might be other reasons why the gap exists
model1.3 <- glm(salary ~ gender, data = current)
kable(tidy(model1.3))
summary(model1.3)
confint(model1.3)
# there exists negative correlation between salary and productivity according to the data given
# worth to mention in the report: higher productivity leads to lower salary
model1.4 <- glm(salary ~ productivity, data = current)
kable(tidy(model1.4))
summary(model1.4)
# The reduced model from the main model - this can be the final model I think
# Tried seniority, gender, quarter, employeeid, team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model1.5 <- lmer(salary ~ gender + seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
summary(model1.5)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.1, model1.5)
# pass_phase1 ~ gender* cv gpa cover_letter (phase1)
model2.1 <- glm(pass_phase1 ~ gender + gpa + extracurriculars + cv + work_experience, family = binomial(link = "logit"), data = phase1_new_applicants)
View(promotion)
promotion %>% ggplot(aes(x = gender, y = promotion)) + geom_boxplot()
# there exists correlation between gender and productivity according to the data given
model1.2 <- glm(productivity ~ gender, data = current)
kable(tidy(model1.2))
summary(model1.2)
# pass_phase1 ~ gender* cv gpa cover_letter (phase1)
model2.1 <- glm(pass_phase1 ~ gender + gpa + extracurriculars + cv + work_experience, family = binomial(link = "logit"), data = phase1_new_applicants)
# Import cleaned data
current <- read_csv("clean/current.csv")
promotion <- read_csv("clean/promotion.csv")
final_hires <- read_csv("clean/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("clean/phase1_new.csv")
phase2_new_applicants <- read_csv("clean/phase2_new.csv")
phase3_new_applicants <- read_csv("clean/phase3_new.csv")
# pass_phase1 ~ gender* cv gpa cover_letter (phase1)
model2.1 <- glm(pass_phase1 ~ gender + gpa + extracurriculars + cv + work_experience, family = binomial(link = "logit"), data = phase1_new_applicants)
write.csv(phase3_new_applicants, "../output/clean/phase3_new.csv")
phase1_new_applicants
library(lmtest)
library(tidyverse)
library(cowplot)
library(lme4)
library(ggpubr)
library(knitr)
library(tableone)
library(broom)
#install.packages("tableone")
# this should supress all code and messages
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
# Import cleaned data
current <- read_csv("clean/current.csv")
promotion <- read_csv("clean/promotion.csv")
final_hires <- read_csv("clean/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("clean/phase1_new.csv")
phase2_new_applicants <- read_csv("clean/phase2_new.csv")
phase3_new_applicants <- read_csv("clean/phase3_new.csv")
# The main model examine the gender bias, along with other potential biases in current employee remuneration
# Removed "Prefer not to say" from gender since it doesn't provide additional information
# fixed effect: gender, seniority, quarter
# random effect: team, leadership, productivity
current <- current %>% filter(gender != "Prefer not to say")
model1.1 <- lmer(salary ~ gender + seniority + quarter + (1|productivity) + (1|employee_id) + (1|team) + (1|leadership_for_level), data = current)
summary(model1.1)
confint(model1.1)
# there exists correlation between gender and productivity according to the data given
model1.2 <- glm(productivity ~ gender, data = current)
kable(tidy(model1.2))
summary(model1.2)
#This model shows that there is a difference in salary between male and female, but there might be other reasons why the gap exists
model1.3 <- glm(salary ~ gender, data = current)
kable(tidy(model1.3))
summary(model1.3)
confint(model1.3)
# there exists negative correlation between salary and productivity according to the data given
# worth to mention in the report: higher productivity leads to lower salary
model1.4 <- glm(salary ~ productivity, data = current)
kable(tidy(model1.4))
summary(model1.4)
# The reduced model from the main model - this can be the final model I think
# Tried seniority, gender, quarter, employeeid, team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model1.5 <- lmer(salary ~ gender + seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
summary(model1.5)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.1, model1.5)
phase1_new_applicants
# pass_phase1 ~ gender* cv gpa cover_letter (phase1)
model2.1 <- glm(pass_phase1 ~ gender + gpa + extracurriculars + cv + work_experience, family = binomial(link = "logit"), data = phase1_new_applicants)
model2.4 <- glm(final_hired ~ gpa, family = binomial(link = "logit"), data = phase1_new_applicants)
model2.4 <- glm(final_hired.x ~ gpa, family = binomial(link = "logit"), data = phase1_new_applicants)
summary(model2.4)
View(final_hires)
View(phase1_new_applicants)
View(phase2_temp)
final_hires <- read_csv("../input/data/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("../input/data/phase1-new-grad-applicants-2020.csv")
phase2_new_applicants <- read_csv("../input/data/phase2-new-grad-applicants-2020.csv")
phase3_new_applicants <- read_csv("../input/data/phase3-new-grad-applicants-2020.csv")
phase1_new_applicants <- phase1_new_applicants %>%
merge(final_hires, by = "applicant_id", all = TRUE) %>% merge(phase2_temp, by = "applicant_id" & "pass_phase1", all = TRUE)
phase1_new_applicants
# pass_phase1 ~ gender* cv gpa cover_letter (phase1)
model2.1 <- glm(pass_phase1.x ~ gender + gpa + extracurriculars + cv + work_experience, family = binomial(link = "logit"), data = phase1_new_applicants)
View(phase1_new_applicants)
phase1_new_applicants
# pass_phase1 ~ gender* cv gpa cover_letter (phase1)
model2.1 <- glm(pass_phase1.x ~ gender + gpa + extracurriculars + cv + work_experience, family = binomial(link = "logit"), data = phase1_new_applicants)
#### Workspace setup ####
if (!require("remotes")) install.packages("remotes")
remotes::install_github("AndriSignorell/DescTools")
# Import cleaned data
current <- read_csv("clean/current.csv")
promotion <- read_csv("clean/promotion.csv")
final_hires <- read_csv("clean/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("clean/phase1_new.csv")
phase2_new_applicants <- read_csv("clean/phase2_new.csv")
phase3_new_applicants <- read_csv("clean/phase3_new.csv")
# Import cleaned data
current <- read_csv("clean/current.csv")
promotion <- read_csv("clean/promotion.csv")
final_hires <- read_csv("clean/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("clean/phase1_new.csv")
phase2_new_applicants <- read_csv("clean/phase2_new.csv")
phase3_new_applicants <- read_csv("clean/phase3_new.csv")
phase1_new_applicants
# pass_phase1 ~ gender* cv gpa cover_letter (phase1)
model2.1 <- glm(pass_phase1.x ~ gender + gpa + extracurriculars + cv + work_experience, family = binomial(link = "logit"), data = phase1_new_applicants)
summary(model2.1)
# pass_phase2 ~ gender* cv gpa cover_letter tech writing speaking (phase2)
# everyone passed phase 1 has cv
model2.2 <- glm(pass_phase2 ~ gender + team_applied_for + extracurriculars + work_experience + technical_skills + writing_skills + leadership_presence + speaking_skills, family = binomial(link = "logit"), data = phase2_new_applicants)
# pass_phase2 ~ gender* cv gpa cover_letter tech writing speaking (phase2)
# everyone passed phase 1 has cv
model2.2 <- glm(pass_phase2.x ~ gender + team_applied_for + extracurriculars + work_experience + technical_skills + writing_skills + leadership_presence + speaking_skills, family = binomial(link = "logit"), data = phase2_new_applicants)
summary(model2.2)
# final_hired ~ gender* cv gpa cover_letter tech writing speaking rating1 rating2 (phase3)
# everyone passed phase 1 has cv
# too few datapoints model can't converge... the only model that can converge is to use gender
phase3_new_applicants <- phase3_new_applicants %>% mutate(avg = (interviewer_rating_1+interviewer_rating_2)/2)
model2.3 <- glm(final_hired ~ gender, family = binomial(link = "logit"), data = phase3_new_applicants)
# final_hired ~ gender* cv gpa cover_letter tech writing speaking rating1 rating2 (phase3)
# everyone passed phase 1 has cv
# too few datapoints model can't converge... the only model that can converge is to use gender
phase3_new_applicants <- phase3_new_applicants %>% mutate(avg = (interviewer_rating_1+interviewer_rating_2)/2)
model2.3 <- glm(final_hired.x ~ gender, family = binomial(link = "logit"), data = phase3_new_applicants)
View(phase3_new_applicants)
# final_hired ~ gender* cv gpa cover_letter tech writing speaking rating1 rating2 (phase3)
# everyone passed phase 1 has cv
# too few datapoints model can't converge... the only model that can converge is to use gender
phase3_new_applicants <- phase3_new_applicants %>% mutate(avg = (interviewer_rating_1+interviewer_rating_2)/2)
model2.3 <- glm(final_hired.x.x ~ gender, family = binomial(link = "logit"), data = phase3_new_applicants)
# final_hired ~ gender* cv gpa cover_letter tech writing speaking rating1 rating2 (phase3)
# everyone passed phase 1 has cv
# too few datapoints model can't converge... the only model that can converge is to use gender
phase3_new_applicants <- phase3_new_applicants %>% mutate(avg = (interviewer_rating_1+interviewer_rating_2)/2)
model2.3 <- glm(final_hired.x.x ~ gender.x, family = binomial(link = "logit"), data = phase3_new_applicants)
summary(model2.3)
#table(phase3_new_applicants$gender, phase3_new_applicants$final_hired)
table(phase3_new_applicants$avg)
#Import Data
black_saber_current_employees <- read_csv("../input/data/black-saber-current-employees.csv")
final_hires <- read_csv("../input/data/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("../input/data/phase1-new-grad-applicants-2020.csv")
phase2_new_applicants <- read_csv("../input/data/phase2-new-grad-applicants-2020.csv")
phase3_new_applicants <- read_csv("../input/data/phase3-new-grad-applicants-2020.csv")
library(tidyverse)
library(DescTools)
#Import Data
black_saber_current_employees <- read_csv("../input/data/black-saber-current-employees.csv")
final_hires <- read_csv("../input/data/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("../input/data/phase1-new-grad-applicants-2020.csv")
phase2_new_applicants <- read_csv("../input/data/phase2-new-grad-applicants-2020.csv")
phase3_new_applicants <- read_csv("../input/data/phase3-new-grad-applicants-2020.csv")
# Removing the dollar signs in current employees data
black_saber_current_employees$salary <- as.numeric(gsub('[$,]','',black_saber_current_employees$salary))
# Add a quarter variable indicating the financial quarter but not the years
black_saber_current_employees<- black_saber_current_employees %>% mutate(quarter = as.character(ifelse(StrRight(financial_q, 1) == '1', '1',
ifelse(StrRight(financial_q, 1) == '2',
'2', ifelse(StrRight(financial_q, 1) == '3',
'3', ifelse(StrRight(financial_q, 1) == '4', '4', financial_q))))))
# Add a financial year variable indicating the financial year but not the quarters
black_saber_current_employees<- black_saber_current_employees %>% mutate(year = as.numeric(StrLeft(financial_q, 4)))
# Combined a few job seniority levels, ie. combined entry-level, junior I II III into junior, senior I II III into senior
black_saber_current_employees<- black_saber_current_employees %>% mutate(seniority = ifelse(role_seniority == 'Entry-level' | StrLeft(role_seniority, 6)
== 'Junior', 'Junior', ifelse(StrLeft(role_seniority, 6) == 'Senior',
'Senior', role_seniority)))
current <- black_saber_current_employees
promotion <- current %>% select(employee_id, role_seniority)
promotion <- unique(promotion)
promotion <- promotion %>% group_by(employee_id) %>% mutate(promotion =n_distinct(role_seniority) - 1)
promotion <- merge(current, promotion, by = "employee_id", all.x = TRUE)
promotion <- promotion %>% select(employee_id, gender, promotion) %>% filter(gender != "Prefer not to say")
promotion <- unique(promotion)
# If the applicant is hired, final_hired = 1, otherwise final_hired = NA.
final_hires <- final_hires %>% mutate(final_hired = 1)
# If the applicant passed phase1, pass_phase1 = 1, otherwise = NA.
phase2_temp <- phase2_new_applicants %>%
select(applicant_id, technical_skills) %>% rename(pass_phase1 = technical_skills) %>% mutate(pass_phase1 = 1)
# If the applicant passed phase2, pass_phase2 = 1, otherwise = NA.
phase3_temp <- phase3_new_applicants %>%
select(applicant_id, interviewer_rating_1) %>% rename(pass_phase2 = interviewer_rating_1) %>% mutate(pass_phase2 = 1)
phase1_new_applicants <- phase1_new_applicants %>%
merge(final_hires, by = "applicant_id", all = TRUE) %>% merge(phase2_temp, by = "applicant_id", all = TRUE)
phase1_new_applicants
phase1_new_applicants <- phase1_new_applicants %>%
mutate(pass_phase1 = ifelse(is.na(pass_phase1), 0, 1)) %>% mutate(final_hired = ifelse(is.na(final_hired), 0, 1))
phase2_new_applicants <- phase2_new_applicants %>%
merge(final_hires, by = "applicant_id", all = TRUE)%>% merge(phase3_temp, by = "applicant_id", all = TRUE)
phase2_new_applicants <- phase2_new_applicants %>%
mutate(pass_phase2 = ifelse(is.na(pass_phase2), 0, 1)) %>% mutate(final_hired = ifelse(is.na(final_hired), 0, 1))
phase2_temp1 <- phase2_new_applicants %>% select(-final_hired, -pass_phase2)
phase3_new_applicants <- phase3_new_applicants %>%
merge(final_hires, by = "applicant_id", all = TRUE) %>% inner_join(phase2_temp1, by = "applicant_id")
phase3_new_applicants <- phase3_new_applicants %>%
mutate(final_hired = ifelse(is.na(final_hired), 0, 1))
#Export cleaned data
write.csv(black_saber_current_employees, "../output/clean/current.csv")
write.csv(phase1_new_applicants, "../output/clean/phase1_new.csv")
write.csv(phase2_new_applicants, "../output/clean/phase2_new.csv")
write.csv(phase3_new_applicants, "../output/clean/phase3_new.csv")
write.csv(promotion, "../output/clean/promotion.csv")
library(lmtest)
library(tidyverse)
library(cowplot)
library(lme4)
library(ggpubr)
library(knitr)
library(tableone)
library(broom)
library(psycho)
install.packages("psycho")
library(lmtest)
library(tidyverse)
library(cowplot)
library(lme4)
library(ggpubr)
library(knitr)
library(tableone)
library(broom)
library(psycho)
#install.packages("tableone")
# this should supress all code and messages
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
# Import cleaned data
current <- read_csv("clean/current.csv")
promotion <- read_csv("clean/promotion.csv")
final_hires <- read_csv("clean/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("clean/phase1_new.csv")
phase2_new_applicants <- read_csv("clean/phase2_new.csv")
phase3_new_applicants <- read_csv("clean/phase3_new.csv")
# The main model examine the gender bias, along with other potential biases in current employee remuneration
# Removed "Prefer not to say" from gender since it doesn't provide additional information
# fixed effect: gender, seniority, quarter
# random effect: team, leadership, productivity
current <- current %>% filter(gender != "Prefer not to say")
model1.1 <- lmer(salary ~ gender + seniority + quarter + (1|productivity) + (1|employee_id) + (1|team) + (1|leadership_for_level), data = current)
summary(model1.1)
#confint(model1.1)
# The main model examine the gender bias, along with other potential biases in current employee remuneration
# Removed "Prefer not to say" from gender since it doesn't provide additional information
# fixed effect: gender, seniority, quarter
# random effect: team, leadership, productivity
current <- current %>% filter(gender != "Prefer not to say")
model1.1 <- lmer(salary ~ gender + seniority + quarter + (1|productivity) + (1|employee_id) + (1|team) + (1|leadership_for_level), data = current)
summary(model1.1)
confint(model1.1)
# there exists correlation between gender and productivity according to the data given
model1.2 <- glm(productivity ~ gender, data = current)
kable(tidy(model1.2))
summary(model1.2)
# The reduced model from the main model - this can be the final model I think
# Tried seniority, gender, quarter, employeeid, team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model2 <- lmer(salary ~ gender + year + seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
#summary(model1.5)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.1, model2)
# The reduced model from the main model - this can be the final model I think
# Tried seniority, gender, quarter, employeeid, team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model2 <- lmer(salary ~ gender + year + seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
#summary(model1.5)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.1, model2)
# The reduced model from the main model - this can be the final model I think
# Tried seniority, gender, quarter, employeeid, team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model2 <- lmer(salary ~ gender + year + seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
#summary(model1.5)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model2, model1.1)
# The reduced model from the main model - this can be the final model I think
# Tried seniority, gender, quarter, employeeid, team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model2 <- lmer(salary ~ gender + year + seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
#summary(model1.5)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model2, model1.1)
# The main model examine the gender bias, along with other potential biases in current employee remuneration
# Removed "Prefer not to say" from gender since it doesn't provide additional information
# fixed effect: gender, seniority, quarter
# random effect: team, leadership, productivity
current <- current %>% filter(gender != "Prefer not to say")
model1.1 <- lmer(salary ~ gender + seniority + quarter + (1|productivity) + (1|employee_id) + (1|team) + (1|leadership_for_level), data = current)
summary(model1.1)
#confint(model1.1)
# The reduced model from the main model - this can be the final model I think
# Tried seniority, gender, quarter, employeeid, team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model2 <- lmer(salary ~ gender + year + seniority + quarter + (1|team) + (1|productivity) + (1|employee_id), data = current)
#summary(model1.5)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model2, model1.1)
# Calculate average productivity score for each employee
current %>% select(employee_id, productivity) %>% group_by(employee_id) %>% summarise_at(vars(productivity),
list(name = mean))
# Calculate average productivity score for each employee
temp_promotion <- current %>% select(employee_id, productivity) %>% group_by(employee_id) %>% summarise_at(vars(productivity),
list(avg_productivity = mean))
promotion <- inner_join(promotion, temp_promotion, by = "employee_id")
write.csv(promotion, "../output/clean/promotion.csv")
# Import cleaned data
current <- read_csv("clean/current.csv")
promotion <- read_csv("clean/promotion.csv")
final_hires <- read_csv("clean/final-hires-newgrad_2020.csv")
phase1_new_applicants <- read_csv("clean/phase1_new.csv")
phase2_new_applicants <- read_csv("clean/phase2_new.csv")
phase3_new_applicants <- read_csv("clean/phase3_new.csv")
promotion
model3.1 <- glm(promotion ~ gender + avg_productivity, data = promotion)
kable(tidy(model3.1))
summary(model3.1)
model3.1 <- glm(promotion ~ gender + avg_productivity, data = promotion)
kable(tidy(model3.1))
summary(model3.1)
# The main model examine the gender bias, along with other potential biases in current employee remuneration
# Removed "Prefer not to say" from gender since it doesn't provide additional information
# fixed effect: gender, seniority, quarter, productivity
# random effect: team, leadership, employee id
current <- current %>% filter(gender != "Prefer not to say")
model1.1 <- lmer(salary ~ gender + seniority + quarter + productivity + (1|employee_id) + (1|team) + (1|leadership_for_level), data = current)
summary(model1.1)
confint(model1.1)
# The reduced model from the main model - this can be the final model I think
# Tried seniority, gender, quarter, employeeid, team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model1.8 <- lmer(salary ~ gender + seniority + quarter + (1|productivity) + (1|employee_id) + (1|team) + (1|leadership_for_level), data = current)
summary(model1.8)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.1, model1.8)
# The reduced model from the main model - this can be the final model I think
# Tried seniority, gender, quarter, employeeid, team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model1.8 <- lmer(salary ~ gender + seniority + quarter + (1|productivity) + (1|employee_id) + (1|team) + (1|leadership_for_level), data = current)
summary(model1.8)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.1, model1.8)
# The reduced model from the main model - this can be the final model I think
# Tried seniority, gender, quarter, employeeid, team, productivity for level from the predictors and the reduced model has a worse performance comparing to the full model
# Tried removing leadership_for_level and the reduced model had a better performance comparing to the original, therefore, it is not necessary to include this predictor into the model
model1.8 <- lmer(salary ~ gender + seniority + quarter + (1|employee_id) + (1|team) + (1|leadership_for_level), data = current)
summary(model1.8)
#confint(model1.5)
# Likelihood ratio test comparing the two models, small p value indicating the second model is better
lmtest::lrtest(model1.1, model1.8)
# there exists correlation between gender and productivity according to the data given
model1.2 <- glm(productivity ~ gender, data = current)
kable(tidy(model1.2))
summary(model1.2)
